{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intend to experiment with sentiment analysis (sentence classification) using different word\n",
    "embeddings and the Sentiment140 dataset containing labeled Twitter tweets. More specifically,\n",
    "we intend to train our own word embeddings using word2vec and then use those with a deep\n",
    "learning sentiment analysis model (TBD: LSTM/GRU/Transformer) that we will create using\n",
    "Pytorch. The main experiments we will perform are\n",
    "- Use Pytorch’s trainable embeddings with random initialization\n",
    "- Use Pytorch’s trainable embeddings with our trained word2vec initialization\n",
    "- Only use our trained word2vec embeddings as inputs\n",
    "\n",
    "and then compare the accuracy results for the sentiment analysis task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would suggest training several sets of your own embeddings (experiment with the parameters to see how they influence the final vectors). Then, compare the sets of embeddings outside of your system (analogies,odd-one-out...), so you can set some expectations about what embeddings might yield the best result for your task. Finally, look at how the vectors perform in your system and analyze if you expected such result and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
    "\n",
    "- https://github.com/hietalajulius/deep-learning-aalto/blob/master/Classifier.ipynb\n",
    "\n",
    "- https://www.kaggle.com/paoloripamonti/twitter-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.vocab\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>oop wrong url thing work mind brain foggi life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yes fantast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>pretttyyi pleaseee tweet mileycsupport reallll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>yep heard everi sad song twitter safe say far ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>oh got blush like littl girl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1     oop wrong url thing work mind brain foggi life\n",
       "1       1                                        yes fantast\n",
       "2       1  pretttyyi pleaseee tweet mileycsupport reallll...\n",
       "3       0  yep heard everi sad song twitter safe say far ...\n",
       "4       1                       oh got blush like littl girl"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/processed_train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained word embeddings\n",
    "- word2Vec\n",
    "- Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/C%20-%20Loading%2C%20Saving%20and%20Freezing%20Embeddings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(tokenize= 'spacy',\n",
    "                            tokenizer_language='en_core_web_sm',\n",
    "                            lower=True)\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.float)\n",
    "\n",
    "datafields = [('Sentiment', LABEL), ('SentimentText', TEXT)]\n",
    "\n",
    "train, val, test = torchtext.data.TabularDataset.splits(path='data/',\n",
    "                                                  train='processed_train.csv',\n",
    "                                                  validation='processed_val.csv',\n",
    "                                                  test='processed_test.csv',\n",
    "                                                  format='csv',\n",
    "                                                  skip_header=True,\n",
    "                                                  fields=datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use pretrained embeddings glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 10002\n",
      "Unique tokens in LABEL vocabulary: 2\n",
      "[('go', 88779), ('get', 70792), ('day', 67839), ('good', 59384), ('work', 56051), ('like', 53493), ('love', 52734), ('quot', 47034), ('got', 45559), ('today', 43640), ('time', 42450), ('nt', 39689), ('lol', 38152), ('thank', 38138), ('back', 36807), ('want', 36771), ('one', 36690), ('i', 36474), ('miss', 36311), ('u', 35543)]\n",
      "['<unk>', '<pad>', 'go', 'get', 'day', 'good', 'work', 'like', 'love', 'quot']\n",
      "defaultdict(None, {'0': 0, '1': 1})\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE=10000\n",
    "TEXT.build_vocab(train, vectors=GloVe(name=\"6B\", dim=100),\n",
    "                 max_size=10000, min_freq=10)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
    "\n",
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "\n",
    "print(TEXT.vocab.itos[:10])\n",
    "\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create own vocab from our train dataset tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 1\n",
      "[('go', 6658), ('work', 5206), ('get', 4904), ('day', 4589), ('miss', 3484), ('nt', 3416), ('like', 3383), ('want', 3272), ('today', 3248), ('back', 3125), ('got', 3075), ('feel', 2861), ('time', 2672), ('i', 2556), ('good', 2452), ('realli', 2422), ('m', 2368), ('still', 2367), ('wish', 2268), ('sad', 2267)]\n",
      "['<unk>', '<pad>', 'go', 'work', 'get', 'day', 'miss', 'nt', 'like', 'want']\n",
      "defaultdict(None, {'0': 0})\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train, max_size=MAX_VOCAB_SIZE, min_freq=10)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
    "\n",
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "\n",
    "print(TEXT.vocab.itos[:10])\n",
    "\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nglove = vocab.Glove(name='6B', dim=100)\\n\\n\\nclosest(glove, get_vector(glove, 'paper'))\\n\\nanalogy(glove, 'moon', 'night', 'sun')\\n\\nown_embeddings = TEXT.vocab\\n\\nclosest(own_embeddings, get_vector(own_embeddings, 'paper'))\\n\\nanalogy(own_embeddings, 'moon', 'night', 'sun')\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vector(embeddings, word):\n",
    "    \n",
    "    return embeddings.vectors(embeddings.stoi[word])\n",
    "\n",
    "\n",
    "def closest(embeddings, vector, n=6):\n",
    "    disntances = []\n",
    "    for neighbor in embeddings.itos:\n",
    "        distances.append(neighbor, torch.dist(vector, get_vactor(embeddings, neighbor)))\n",
    "    \n",
    "    return sorted(distances, key=lambda x: x[1])[:n]\n",
    "\n",
    "\n",
    "def analogy(embeddings, w1, w2, w3, n=6):\n",
    "    \n",
    "    closest_words = closest(embeddings,\n",
    "                           get_vector(embeddings, w2) \\\n",
    "                            - get_vector(embeddings, w1) \\\n",
    "                            + get_vector(embeddings, w3),\n",
    "                           n + 3)\n",
    "    closest_words = [x for x in closest_words if x[0] not in [w1, w2, w3]][:n]\n",
    "    \n",
    "    return closest_words\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "glove = vocab.Glove(name='6B', dim=100)\n",
    "\n",
    "\n",
    "closest(glove, get_vector(glove, 'paper'))\n",
    "\n",
    "analogy(glove, 'moon', 'night', 'sun')\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# minimise badding for each sentence\n",
    "train_iterator, val_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
    "                                (train, val, test),\n",
    "                                batch_size=64,\n",
    "                                sort_key=lambda x: len(x.SentimentText),\n",
    "                                sort_within_batch=False,\n",
    "                                device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim,\n",
    "                output_dim, n_layers, bidirectional, dropout, drop_out_dense=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          hidden_dim,\n",
    "                         num_layers=n_layers,\n",
    "                         bidirectional=bidirectional,\n",
    "                         dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(drop_out_dense)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded_text = self.dropout(self.embedding(text))\n",
    "        output, hidden = self.gru(embedded_text)\n",
    "        hidden = self.dropout2(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        x = self.fc(hidden.squeeze(0))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (embedding): Embedding(10002, 100)\n",
      "  (gru): GRU(100, 256, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "n_layers = 2\n",
    "\n",
    "model = GRU(vocab_size=INPUT_DIM, \n",
    "            embedding_dim=EMBEDDING_DIM, \n",
    "            hidden_dim=HIDDEN_DIM, \n",
    "            output_dim=OUTPUT_DIM, \n",
    "            n_layers=n_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=0.1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pretrained embeddings\n",
    "\n",
    "#pretrained_embeddings = TEXT.vocab.vectors\n",
    "#model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model.embedding.weight.data[unk_idx] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[pad_idx] = torch.zeros(EMBEDDING_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.Sentiment)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return model, epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            # print(batch.SentimentText)\n",
    "            if batch.SentimentText.nelement() > 0:\n",
    "                predictions = model(batch.SentimentText).squeeze(1)\n",
    "\n",
    "                loss = criterion(predictions, batch.Sentiment)\n",
    "\n",
    "                acc = binary_accuracy(predictions, batch.Sentiment)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "            #else:\n",
    "                #print(f\"Found a non-empty Tensorlist {batch.SentimentText}\")\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 16m 25s\n",
      "\tTrain Loss: 0.687 | Train Acc: 54.74%\n",
      "\t Val. Loss: 0.676 |  Val. Acc: 57.75%\n",
      "Epoch: 02 | Epoch Time: 16m 31s\n",
      "\tTrain Loss: 0.673 | Train Acc: 58.25%\n",
      "\t Val. Loss: 0.661 |  Val. Acc: 59.43%\n",
      "Epoch: 03 | Epoch Time: 16m 34s\n",
      "\tTrain Loss: 0.663 | Train Acc: 59.77%\n",
      "\t Val. Loss: 0.652 |  Val. Acc: 60.82%\n",
      "Epoch: 04 | Epoch Time: 16m 36s\n",
      "\tTrain Loss: 0.655 | Train Acc: 60.96%\n",
      "\t Val. Loss: 0.644 |  Val. Acc: 61.89%\n",
      "Epoch: 05 | Epoch Time: 16m 31s\n",
      "\tTrain Loss: 0.646 | Train Acc: 62.25%\n",
      "\t Val. Loss: 0.633 |  Val. Acc: 63.44%\n",
      "Epoch: 06 | Epoch Time: 16m 32s\n",
      "\tTrain Loss: 0.630 | Train Acc: 64.36%\n",
      "\t Val. Loss: 0.612 |  Val. Acc: 65.74%\n",
      "Epoch: 07 | Epoch Time: 16m 30s\n",
      "\tTrain Loss: 0.602 | Train Acc: 67.29%\n",
      "\t Val. Loss: 0.582 |  Val. Acc: 68.57%\n",
      "Epoch: 08 | Epoch Time: 16m 31s\n",
      "\tTrain Loss: 0.578 | Train Acc: 69.65%\n",
      "\t Val. Loss: 0.564 |  Val. Acc: 70.53%\n",
      "Epoch: 09 | Epoch Time: 16m 30s\n",
      "\tTrain Loss: 0.564 | Train Acc: 70.85%\n",
      "\t Val. Loss: 0.556 |  Val. Acc: 71.30%\n",
      "Epoch: 10 | Epoch Time: 16m 33s\n",
      "\tTrain Loss: 0.556 | Train Acc: 71.64%\n",
      "\t Val. Loss: 0.549 |  Val. Acc: 72.34%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "#freeze embeddings\n",
    "model.embedding.weight.requires_grad = False\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model, train_loss, train_acc  = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, val_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'sent_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (embedding): Embedding(10002, 100)\n",
      "  (gru): GRU(100, 256, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Test Loss: 0.551 | Test Acc: 72.20%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('sent_model.pt'))\n",
    "print(model)\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100703954696655"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is great\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    n = len(y)\n",
    "    return correct, n\n",
    "\n",
    "def evaluate_cm(model, iterator, criterion):\n",
    "    \n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            # print(batch.SentimentText)\n",
    "            if batch.SentimentText.nelement() > 0:\n",
    "                predictions = model(batch.SentimentText).squeeze(1)\n",
    "\n",
    "                acc = binary_accuracy(predictions, batch.Sentiment)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "            else:\n",
    "                print(f\"Found a non-empty Tensorlist {batch.SentimentText}\")\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got float)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-e9d162a3ab34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred_1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test_1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpredict_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-e9d162a3ab34>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred_1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test_1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpredict_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-6d7e44060899>\u001b[0m in \u001b[0;36mpredict_sentiment\u001b[1;34m(model, sentence)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtokenized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#print(tokenized)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mindexed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got float)"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/processed_test.csv')\n",
    "\n",
    "y_pred_1d = []\n",
    "y_test_1d = list(df_test.target)\n",
    "scores = [predict_sentiment(model, sentence) for sentence in df_test.text]\n",
    "\n",
    "\n",
    "y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=df_train.target.unique(), title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
